*/private static org.apache.flink.api.java.tuple.Tuple2<org.apache.calcite.rel.RelNode, int[]> convertToRowLevelDelete(org.apache.calcite.rel.logical.LogicalTableModify tableModify, org.apache.flink.table.catalog.ContextResolvedTable contextResolvedTable, org.apache.flink.table.connector.sink.abilities.SupportsRowLevelDelete.RowLevelDeleteInfo rowLevelDeleteInfo, java.lang.String tableDebugName, org.apache.flink.table.catalog.DataTypeFactory dataTypeFactory, org.apache.flink.table.planner.calcite.FlinkTypeFactory typeFactory) {
   // get the required columns
   org.apache.flink.table.catalog.ResolvedSchema resolvedSchema = contextResolvedTable.getResolvedSchema(); java.util.Optional<java.util.List<org.apache.flink.table.catalog.Column>> optionalColumns = rowLevelDeleteInfo.requiredColumns();java.util.List<org.apache.flink.table.catalog.Column> requiredColumns = optionalColumns.orElse(resolvedSchema.getColumns());// get the root table scan which we may need rewrite it
   org.apache.calcite.rel.logical.LogicalTableScan tableScan = org.apache.flink.table.planner.connectors.DynamicSinkUtils.getSourceTableScan(tableModify);// get the index for the required columns and extra meta cols if necessary
   org.apache.flink.api.java.tuple.Tuple2<java.util.List<java.lang.Integer>, java.util.List<org.apache.flink.table.catalog.Column.MetadataColumn>> colsIndexAndExtraMetaCols = org.apache.flink.table.planner.connectors.DynamicSinkUtils.getRequireColumnsIndexAndExtraMetaCols(tableScan, requiredColumns, resolvedSchema);java.util.List<java.lang.Integer> colIndexes = colsIndexAndExtraMetaCols.f0;java.util.List<org.apache.flink.table.catalog.Column.MetadataColumn> metadataColumns = colsIndexAndExtraMetaCols.f1;
   // if meta columns size is greater than 0, we need to modify the underlying
   // LogicalTableScan to make it can read meta column
   if (metadataColumns.size() > 0) { resolvedSchema = org.apache.flink.table.planner.connectors.DynamicSinkUtils.addExtraMetaCols(tableModify, tableScan, tableDebugName, metadataColumns, typeFactory);}// create a project only select the required columns for delete
   return org.apache.flink.api.java.tuple.Tuple2.of(org.apache.flink.table.planner.connectors.DynamicSinkUtils.projectColumnsForDelete(tableModify, resolvedSchema, colIndexes, tableDebugName, dataTypeFactory, typeFactory), org.apache.flink.table.planner.connectors.DynamicSinkUtils.getPhysicalColumnIndices(colIndexes, resolvedSchema)); }